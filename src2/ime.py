# -*- coding: utf-8 -*-
"""
ime_tui.py â€” TinyGPT2 å˜èªIMEï¼ˆç¢ºç‡ä»˜ããƒ»BPE/UNK/çµµæ–‡å­—å¯¾å¿œãƒ»TUIãƒ»5ã€œ10æ–‡å­—è£œå®Œï¼‰
- composing: å…¥åŠ›ä¸­ã®èª
- Spaceï¼ˆåŠè§’/å…¨è§’ï¼‰: å¤‰æ›å€™è£œè¡¨ç¤ºï¼å·¡å›
- Enter: å€™è£œç¢ºå®šï¼ˆé¸æŠä¸­ï¼‰ï¼composingã‚’committedã¸ç¢ºå®šï¼ˆéé¸æŠæ™‚ï¼‰
- Backspace: 1æ–‡å­—æˆ»ã‚‹ï¼ˆé¸æŠä¸­ã¯å€™è£œè§£é™¤ï¼‰
- æ•°å­—1-9: å€™è£œãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆé¸æŠ
- ESC: çµ‚äº†

ç‰¹é•·:
- BPEã®éƒ¨åˆ†ãƒˆãƒ¼ã‚¯ãƒ³ã‚„ <unk> ã‚’å«ã‚€é–“ã¯ã€Œæœªå®Œæˆã€ã¨ã¿ãªã—å€™è£œã«å‡ºã•ãªã„
- çµµæ–‡å­—ãªã©å¤šãƒˆãƒ¼ã‚¯ãƒ³æ–‡å­—ã¯1ã‚°ãƒ©ãƒ•ã‚§ãƒ ãŒå®Œæˆã™ã‚‹ã¾ã§å±•é–‹ã‚’ç¶™ç¶š
- 5ã€œ10æ–‡å­—ç¨‹åº¦ã®ã¾ã¨ã¾ã‚Šï¼ˆçŸ­æ–‡ãƒ»èªå¥ï¼‰ã‚’è£œå®Œå€™è£œã¨ã—ã¦ç”Ÿæˆ
"""

import math
import os
import re
import sys
import time
import traceback
import unicodedata
from dataclasses import dataclass

import torch
from tqdm.auto import tqdm


# ===== Windows UTF-8 å¼·åˆ¶ =====
def _force_utf8_console():
    try:
        import ctypes

        ctypes.windll.kernel32.SetConsoleOutputCP(65001)
        ctypes.windll.kernel32.SetConsoleCP(65001)
    except Exception:
        pass
    try:
        sys.stdout.reconfigure(encoding="utf-8", errors="replace")
        sys.stderr.reconfigure(encoding="utf-8", errors="replace")
    except Exception:
        pass


_force_utf8_console()

# ===== è¨­å®š =====
DEBUG = False
CKPT = r"checkpoints_tyny\20251021_175651_latest_000002000.model.pt"
TOKENIZER_JSON = r"tokenizer.json"

BEAM_SIZE = 16
FIRST_STEP_TOPK = 120
STEP_TOPK = 64
MAX_STEPS = 12
TEMPERATURE = 0.8
TARGET_MIN_CHARS = 10
TARGET_MAX_CHARS = 15

BAR_LEN = 8
TOP_EMOJIS = []

try:
    import msvcrt

    IS_WINDOWS = True
except Exception:
    IS_WINDOWS = False

# ===== æ–‡å­—ã‚¯ãƒ©ã‚¹ =====
_HIRA, _KATA, _KANJI, _LATIN, _DIGIT = (
    re.compile(r"[\u3040-\u309F]"),
    re.compile(r"[\u30A0-\u30FF\uFF66-\uFF9D]"),
    re.compile(r"[\u4E00-\u9FFF]"),
    re.compile(r"[A-Za-z]"),
    re.compile(r"[0-9]"),
)
_MARK = re.compile(
    r'[ã€ã€‚ï¼ï¼Œãƒ»â€¦ï¼ï¼Ÿ!?\.\,\(\)\[\]{}ã€Œã€ã€ã€ã€Šã€‹ã€ˆã€‰â€œâ€"\'ï¼/\\:;ã€œï½â€”\s]'
)
SEP_CHARS = set(
    " ã€€ã€ã€‚ï¼ï¼Œãƒ»â€¦ï¼ï¼Ÿ!?ã€‚ã€/\\#@ï¼šã€Œã€ã€ã€ã€Šã€‹ã€ˆã€‰â€œâ€\"'()ï¼ˆï¼‰[]{}ï¼šï¼›;ã€œï½â€”\n\r\t"
)


def _char_class(ch: str) -> str:
    if _MARK.match(ch):
        return "M"
    if _HIRA.match(ch):
        return "H"
    if _KATA.match(ch):
        return "K"
    if _KANJI.match(ch):
        return "C"
    if _DIGIT.match(ch):
        return "D"
    if _LATIN.match(ch):
        return "L"
    return "M"


def _good_chunk(w: str) -> bool:
    if not w:
        return False
    if all(ch in SEP_CHARS for ch in w):
        return False
    if any(ord(ch) < 0x20 for ch in w):
        return False
    return True


def _longest_common_prefix_len(a: str, b: str) -> int:
    i = 0
    L = min(len(a), len(b))
    while i < L and a[i] == b[i]:
        i += 1
    return i


def _contains_unk(tokenizer, ids: list[int], decoded: str) -> bool:
    try:
        sp = getattr(tokenizer, "special", None) or {}
        unk_id = sp.get("<unk>", None)
    except Exception:
        unk_id = None
    if unk_id is not None and any(t == unk_id for t in ids):
        return True
    if "<unk>" in decoded or "\ufffd" in decoded:
        return True
    return False


def _incomplete_grapheme(s: str) -> bool:
    if not s:
        return True
    c = s[-1]
    if unicodedata.combining(c):
        return True
    if c in ("\ufe0f", "\u200d"):
        return True
    RI_START, RI_END = 0x1F1E6, 0x1F1FF
    ri_tail = 0
    for ch in reversed(s):
        cp = ord(ch)
        if RI_START <= cp <= RI_END:
            ri_tail += 1
        else:
            break
    return ri_tail % 2 == 1


def _clamp_idx(idx, cands):
    return 0 if not cands else max(0, min(idx, len(cands) - 1))


def _prob_bar(p: float) -> str:
    return "â–ˆ" * int(round(p * BAR_LEN)) + "â–‘" * (BAR_LEN - int(round(p * BAR_LEN)))


# ===== ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ =====
def _load_model_and_tokenizer():
    model = torch.load(CKPT, map_location="cuda", weights_only=False)
    model.to("cuda").eval()
    from tokenizer import ByteBPETokenizer

    tok = ByteBPETokenizer(TOKENIZER_JSON)
    return model, tok


@dataclass
class Beam:
    ids: list
    logp: float
    text: str
    finished: bool


# ===== 5ã€œ10æ–‡å­—è£œå®Œ =====
@torch.no_grad()
def prob_span_candidates(
    seed_text: str, model, tokenizer, n=10, prefix_constraint: str = ""
):
    device = next(model.parameters()).device

    def _enc(txt: str):
        ids = tokenizer.encode(txt or "")
        return ids if ids else tokenizer.encode(" ")

    seed_ids = _enc(seed_text)
    seed = torch.tensor(seed_ids, dtype=torch.long, device=device)[None, :]
    prefix_ids = _enc(prefix_constraint) if prefix_constraint else []
    prefix_text = tokenizer.decode(prefix_ids) if prefix_ids else ""
    beams = [Beam(ids=list(prefix_ids), logp=0.0, text="", finished=False)]
    results: dict[str, float] = {}
    max_steps = MAX_STEPS + 8
    pbar = tqdm(total=max_steps, desc="ğŸ”®", leave=False, disable=(not DEBUG))
    for step in range(max_steps):
        new_beams = []
        expanded = False
        for b in beams:
            if b.finished:
                new_beams.append(b)
                continue
            x = torch.cat(
                [seed, torch.tensor([b.ids], dtype=torch.long, device=device)], dim=1
            )
            logits = model(x)[:, -1, :] / TEMPERATURE
            probs = torch.softmax(logits, dim=-1)
            k = min(FIRST_STEP_TOPK if step == 0 else STEP_TOPK, probs.size(-1))
            pv, pi = torch.topk(probs, k=k, dim=-1)
            for tid, p in zip(pi[0].tolist(), pv[0].tolist()):
                ids2 = b.ids + [tid]
                logp2 = b.logp + math.log(max(p, 1e-12))
                cont = tokenizer.decode(ids2)
                cut = (
                    _longest_common_prefix_len(cont, prefix_text) if prefix_text else 0
                )
                suffix = cont[cut:]
                if _contains_unk(tokenizer, ids2, cont) or _incomplete_grapheme(suffix):
                    new_beams.append(Beam(ids2, logp2, b.text, False))
                    expanded = True
                    continue
                cand = suffix
                g_len = len(cand)
                finished = False
                out_text = cand
                if g_len < TARGET_MIN_CHARS:
                    finished = False
                elif g_len > TARGET_MAX_CHARS:
                    out_text = cand[:TARGET_MAX_CHARS]
                    finished = True
                else:
                    finished = True
                if not _good_chunk(out_text):
                    continue
                new_beams.append(Beam(ids2, logp2, out_text, finished))
                expanded = True
        new_beams.sort(key=lambda b: b.logp, reverse=True)
        beams = new_beams[:BEAM_SIZE]
        for b in beams:
            if b.finished and _good_chunk(b.text):
                results[b.text] = max(results.get(b.text, -1e9), b.logp)
        pbar.update(1)
        if (len(results) >= n and step >= 3) or not expanded:
            break
    pbar.close()
    if not results:
        return []
    words, lps = zip(*results.items())
    m = max(lps)
    exps = [math.exp(lp - m) for lp in lps]
    Z = sum(exps) or 1
    pairs = [(w, e / Z) for w, e in zip(words, exps) if _good_chunk(w)]
    pairs.sort(
        key=lambda t: (
            -t[1],
            abs(len(t[0]) - (TARGET_MIN_CHARS + TARGET_MAX_CHARS) / 2),
        )
    )
    return pairs[:n]


# ===== UI =====
def _render(committed, composing, cand_probs, idx, selecting):
    sys.stdout.write("\r" + " " * 200 + "\r")
    sys.stdout.write(f"å…¥åŠ›: {committed}|{composing}\n")
    if selecting and cand_probs:
        lines = []
        for i, (w, p) in enumerate(cand_probs, 1):
            mark = "â–¶" if i - 1 == idx else "  "
            lines.append(f"{mark} {i:>2}. {w} {p*100:5.1f}% {_prob_bar(p)}")
        sys.stdout.write("\n".join(lines))
        sys.stdout.write("\nï¼ˆSpace æ¬¡ / Enter ç¢ºå®š / 1-9 é¸æŠ / BS æˆ»ã‚‹ / ESC çµ‚äº†ï¼‰")
    else:
        sys.stdout.write("å€™è£œ: ï¼ˆSpaceã§å¤‰æ›ã€‚Enterã§ç¢ºå®šã€‚å…¨è§’/åŠè§’Spaceã©ã¡ã‚‰ã‚‚å¯ï¼‰")
    sys.stdout.flush()


# ===== ãƒ«ãƒ¼ãƒ— =====
def _windows_loop(model, tokenizer):
    os.system("")
    try:
        os.system("chcp 65001 >NUL")
    except Exception:
        pass
    committed, composing = "", ""
    selecting = False
    cand_probs = []
    idx = 0
    last_space = 0
    print("TinyGPT2 IME â€” Spaceå¤‰æ› / Enterç¢ºå®š / ESCçµ‚äº†")
    _render(committed, composing, cand_probs, idx, selecting)
    while True:
        ch = msvcrt.getwch()
        if ch in ("\x00", "\xe0"):
            _ = msvcrt.getwch()
            continue
        if ch == "\x1b":
            print("\nâ¹ çµ‚äº†")
            break
        if ch == "\x08":
            if selecting:
                selecting = False
                cand_probs = []
            else:
                if composing:
                    composing = composing[:-1]
                elif committed:
                    committed = committed[:-1]
            _render(committed, composing, cand_probs, idx, selecting)
            continue
        if ch == "\r":
            if selecting and cand_probs:
                composing += cand_probs[idx][0]
                selecting = False
                cand_probs = []
            else:
                committed += composing
                composing = ""
            _render(committed, composing, cand_probs, idx, selecting)
            continue
        if ch in (" ", "\u3000"):
            now = time.time()
            if now - last_space < 0.06:
                continue
            last_space = now
            if selecting:
                idx = (idx + 1) % len(cand_probs) if cand_probs else 0
                _render(committed, composing, cand_probs, idx, selecting)
                continue
            if not composing:
                tail = re.findall(
                    r'([^\sã€ã€‚ï¼ï¼Ÿâ€¦ãƒ»ã€Œã€ã€ã€ã€Šã€‹ã€ˆã€‰â€œâ€"\'/\\:;ã€œï½â€”-]+)$', committed
                )
                if tail:
                    composing = tail[0]
                    committed = committed[: -len(composing)]
                else:
                    committed += ch
                    _render(committed, composing, cand_probs, idx, selecting)
                    continue
            selecting = True
            try:
                pairs = prob_span_candidates(
                    committed, model, tokenizer, n=30, prefix_constraint=composing
                )
                cand_probs = pairs[:10] if pairs else []
            except Exception as e:
                if DEBUG:
                    print(e)
                    traceback.print_exc()
                cand_probs = []
            if not cand_probs:
                selecting = False
                _render(committed, composing, cand_probs, idx, selecting)
                continue
            idx = 0
            _render(committed, composing, cand_probs, idx, selecting)
            continue
        if "1" <= ch <= "9" and selecting and cand_probs:
            i = ord(ch) - ord("1")
            if i < len(cand_probs):
                idx = i
            _render(committed, composing, cand_probs, idx, selecting)
            continue
        composing += ch
        if selecting:
            selecting = False
            cand_probs = []
        _render(committed, composing, cand_probs, idx, selecting)


def _fallback_loop(model, tokenizer):
    print("TinyGPT2 IMEï¼ˆç°¡æ˜“ï¼‰ â€” :space å¤‰æ› / :enter ç¢ºå®š / :quit çµ‚äº†")
    committed, composing = "", ""
    while True:
        print(f"\nå…¥åŠ›: {committed}|{composing}")
        cmd = input("[æ–‡å­—å…¥åŠ›] / [:space] / [:enter] / [:quit] > ").strip()
        if cmd == ":quit":
            print("bye")
            break
        if cmd == ":enter":
            committed += composing
            composing = ""
            continue
        if cmd == ":space":
            pairs = prob_span_candidates(
                committed, model, tokenizer, n=30, prefix_constraint=composing
            )
            pairs = pairs[:10] if pairs else []
            for i, (w, p) in enumerate(pairs, 1):
                print(f"{i:>2}. {w} {p*100:5.1f}% {_prob_bar(p)}")
            sel = input("ç•ªå· / Enterã§1ç•ªç¢ºå®š > ").strip()
            if sel.isdigit():
                i = int(sel) - 1
                if 0 <= i < len(pairs):
                    composing += pairs[i][0]
            else:
                if pairs:
                    composing += pairs[0][0]
            continue
        composing += cmd


def main():
    try:
        model, tokenizer = _load_model_and_tokenizer()
    except Exception as e:
        print("[load error]", e)
        traceback.print_exc()
        return
    if IS_WINDOWS:
        _windows_loop(model, tokenizer)
    else:
        _fallback_loop(model, tokenizer)


if __name__ == "__main__":
    main()
